{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning and its application in Muon Tomography\n",
    "\n",
    "Machine Learning inspired techniques can be applied to Muon Tomography to resolve many of associated problems. The two problems of interest to us are *low resolution tomograms* and *data inefficiency*. In this notebook, I am discussing the use of ML as applied to MT to solve problem of data inefficiency. \n",
    "\n",
    "## Data Inefficiency Problem\n",
    "\n",
    "![pic](mt.jpeg)\n",
    "\n",
    "We define \"good muon events\" as events with 4 by 4 coincidence hits. Such events have defined spatial points in both top and bottom trays. For example, for the hit on the right the information\n",
    "$$ A (x_1,y_1) $$\n",
    "$$ B (x_2,y_2) $$\n",
    "\n",
    "are known. Due to limited capabilities of our instruments, such events are rare (less than $40\\%$ withour best set up) with many events following the trend of the hit on the left. \n",
    "\n",
    "$$ C (x_3,y_3) $$\n",
    "$$ D (x_4,?) $$\n",
    "\n",
    "We know that $y_4 \\in (y_{min}, y_{max})$ and is discernable by $y_{res}$ which is the limited hardware spatial resolution of the telescope. Now, the question is what this $y_4$ may be? \n",
    "\n",
    "Once we know how to address this question, we can reduce our data redundancy drastically and improve our overall resolution and efficiency of our schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Track reconstruction using non-perfect events\n",
    "\n",
    "Each event is assigned a probability that describes the likelihood of using information from that event to reconstruct the muon track. Such a scheme means that events with 4 by 4 coincidence hits have a probability of 1 and events with no hits have probability 0. Events with 3 by 4 hits are thus also assigned a probability.\n",
    "\n",
    "The way we assign this probability requires the use of some neural networks - *RNN's and LSTM's*. The idea is as follows:\n",
    "\n",
    "1. Contextualize the entire dataset into a RNN framework\n",
    "2. Calculate key statistics of overall dataset and individual events\n",
    "3. Locate events with missing information (i.e. not perfect 4 by 4 coincidence hits)\n",
    "4. Assign probabilities to candidates for the missing information using wholistic statistics, TDC data, and the angular distribution of muons.\n",
    "4. Use RNN's and LSTM's to predict the missing datum in 3 by 4 events using the probabilistic approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Probability distribution of the muon hit of a single spatial dimension\n",
    "\n",
    "Using the coordinate with full information *(C in our case)* and the other spatial coordinate ($x_4$), we assign probabilites to each $y_i \\in (y_{min}, y_{max})$. Formally, it can be represented using Bayes' theorem.\n",
    "\n",
    "$$ P(y_4 = y_i | x_3,y_3,x_4)  $$\n",
    "\n",
    "Now, the question is how do we create such a probability distribution? What controlled/measured factors can help us make such decisions?\n",
    "\n",
    "### No information known\n",
    "\n",
    "When we know previous/extra information about the muon hit, one can imagine the distribution is uniform on the space of the spatial dimension.\n",
    "\n",
    "$$ P(y_4 = y_i | x_3,y_3,x_4) \\sim \\mathcal{U} (y_{min}, y_{max})  $$\n",
    "\n",
    "### One spatial coordinate and one single spatial dimension known\n",
    "\n",
    "The distribution for such a case is much more complicated. The following are some ways of generating the distribution.\n",
    "\n",
    "#### Exact Aggregate Data Approach\n",
    "\n",
    "In this approach, we simply assign the probabilities based on the most likely value from the set of \"good\" events that share the exact coordinates with the event under consideration. The probability simply becomes a fraction of the two aggregate type of events.\n",
    "\n",
    " $$ f_1(y_i) =  P(y_4 = y_i) = \\frac{E(y_i,x_3,y_3,x_4)}{E(x_3,y_3,x_4)} $$\n",
    "    \n",
    "    \n",
    "#### Similar Aggregate Data Approach\n",
    "    \n",
    "We do a similar thing like the **Exact Aggregate Data Approach** with the added consideration of neighbors to influence the statistic. For a tolerance unit of $\\chi$. The following is the probability distribution.\n",
    "\n",
    " $$f_2(y_i) = P(y_4 = y_i) = \\frac{E(y_i,x_3+\\chi,y_3+\\chi,x_4+\\chi)}{E(x_3+\\chi,y_3+\\chi,x_4+\\chi)} $$\n",
    "   \n",
    "   \n",
    "#### Shift of TDC Approach  \n",
    "\n",
    "Since, we have demonstrated that TDC values are correlated with the transverse distance of the muon hit along the scintilator bar. It is possible to extrapolate 2D information from such values. In this approach, we do just that to determine the missing spatial dimension.\n",
    "\n",
    "Let's consider the following case of event D.\n",
    "\n",
    "**Y and X direction has been mistakenly reveresed here in the plots**\n",
    "\n",
    "![pic2](sec.png)\n",
    "\n",
    "We are classing the groups of muon hits along the readout channel of event D into 4 arbitrary groups - W, Q,Y,T. We know that there is a relationship between the average TDC measured at the one of the channels of this group and the measured distance along the axis as illustrated by the following figure. \n",
    "\n",
    "![pic3](demo1.png)\n",
    "\n",
    "The discernable peaks/mean here represent the different \"classes\". The vector of such statistic is directly correlated with the value of the missing orthogonal dimension. Using this relationship - $y_p = m\\mu + c$-, we can predict the missing dimension ($y_4$ in our case).\n",
    "\n",
    "![pic4](demo2.png)\n",
    "\n",
    "We define a function $g(y_4 = y_1)$ such that\n",
    "\n",
    "$$g(y_4 = y_i) = \\frac{\\lvert (m\\mu_{known} + c)-y_i \\lvert}{y_{min}+y_{max}}$$\n",
    "\n",
    "Thus,\n",
    "\n",
    " $$f_3(y_i) = P(y_4 = y_i | \\mu = \\mu_{known}) =  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 - g(y_4 = y_i)  & g(y_4 = y_i) \\le 1 \\\\\n",
    "      0 & g(y_4 = y_i) \\ge 1 \\\\\n",
    "\\end{array} \n",
    "\\right. $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Common Zenith Angle Approach\n",
    "\n",
    "In this approach, we select the missing spatial dimension such that the angle resembles the most common zenith angle, $\\alpha_{mean}$ with $\\vec \\alpha$ being the vector of angles computed from the data set.\n",
    "\n",
    "$$ \\alpha_{mean} = E(\\vec \\alpha) $$\n",
    "\n",
    "Since the space of $y_i$ is discrete. It is, thus, possible to generate a zenith angle distribution over such a space given the set $x_3,y_3,x_4$ is known as is the case in the event of interest.\n",
    "\n",
    "For example, lets consider such an arbitrary distribution.\n",
    "\n",
    "<img src=\"plot2.png\" alt=\"Example\" width=\"600\" height=\"800\">\n",
    "\n",
    "We define a function $d(y_i)$ (given $x_3,y_3,x_4$) as follows:\n",
    "\n",
    "$$ d(y_i | x_3,y_3,x_4) = \\frac{\\lvert \\alpha_{mean} - \\alpha_i(y_i) \\lvert}{\\alpha_{mean}}  $$\n",
    "\n",
    "Thus, using this function we generate a probability distribution that selects for the most common zenith angle.\n",
    "\n",
    " $$f_4(y_i) = P(y_4 = y_i) = 1 - d(y_i | x_3,y_3,x_4)  $$\n",
    "\n",
    "The best method should be some combination of all such approaches. This is where ML comes in. The ML scheme would work to solve for the coffecients that of such a weighted sum to **maximize** resolution of tomogram and **minimize** data inefficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying ML\n",
    "\n",
    "### Comprehensive Probability Function\n",
    "$$ P(y_4 = y_i) = Af_1(y_i) + Bf_2(y_i) + Cf_3(y_i) + Df_4(y_i)$$\n",
    "\n",
    "Let $\\vec \\theta$ be the vector of the coefficients.\n",
    "\n",
    "$$\\vec \\theta = \\begin{bmatrix}\n",
    "    A \\\\\n",
    "    B \\\\\n",
    "    C \\\\\n",
    "    D\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "### Objective Function for Training\n",
    "\n",
    "Here, $E_\\text{total}$ is the total number of events in the data set and $E_\\text{used}(\\theta)$ is the number of events that are being used for analysis purposes as dictated by $\\theta$.\n",
    "\n",
    "$$\\underset{\\boldsymbol{\\theta}}\n",
    "{{\\text{minimize}}}\\;\\; E_\\text{total} - E_\\text{used}(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the Algorithm\n",
    "\n",
    "For the implementation of the algorithm discussed I will be using runs **56 (with bricks)** and **63 (no bricks)**. The reason behind this selection is to compare the improvement *(if any)* as a result of this new algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the files\n",
    "from MuonDataFrame import *\n",
    "file1 = \"processed_data/events_data_frame_56.h5\"\n",
    "file2 = \"processed_data/events_data_frame_63.h5\"\n",
    "\n",
    "# create the MDFO's\n",
    "\n",
    "## with bricks\n",
    "mdfob = MuonDataFrame(file1, isNew=False, d1=\"last\") #Muon Data Frame Object \n",
    "mdfb = mdfob.events_df\n",
    "\n",
    "## no bricks\n",
    "mdfonb = MuonDataFrame(file2, isNew=False, d1=\"last\") #Muon Data Frame Object \n",
    "mdfnb = mdfonb.events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_num', 'event_time', 'deadtime', 'ADC', 'TDC', 'l1hit', 'l2hit',\n",
       "       'l3hit', 'l4hit', 'r1hit', 'r2hit', 'r3hit', 'r4hit', 'SCh0', 'SCh1',\n",
       "       'SCh2', 'SCh3', 'SCh4', 'SCh5', 'SCh6', 'SCh7', 'SCh8', 'SCh9', 'SCh10',\n",
       "       'SCh11', 'L1', 'R1', 'L2', 'R2', 'L3', 'R3', 'L4', 'R4', 'TopCounter',\n",
       "       'BottomCounter', 'sumL1', 'sumL2', 'sumL3', 'sumL4', 'diffL1', 'diffL2',\n",
       "       'diffL3', 'diffL4', 'asymL1', 'asymL2', 'asymL3', 'asymL4', 'numLHit',\n",
       "       'theta_x1', 'theta_y1', 'theta_x2', 'theta_y2', 'z_angle'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify events with $3/4$ hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfb3 = mdfb.loc[mdfb['numLHit'] == 7]\n",
    "mdfnb3 = mdfnb.loc[mdfnb['numLHit'] == 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we identify the missing spatial coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfb_cp = mdfb3[['event_num','asymL1','asymL2','asymL3','asymL4']]\n",
    "mdfnb_cp = mdfnb3[['event_num','asymL1','asymL2','asymL3','asymL4']]\n",
    "\n",
    "# bricks\n",
    "mdfb_cp['missing'] = mdfb_cp.isna().dot(mdfb_cp.columns)\n",
    "# no bricks\n",
    "mdfnb_cp['missing'] = mdfnb_cp.isna().dot(mdfnb_cp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_num</th>\n",
       "      <th>asymL1</th>\n",
       "      <th>asymL2</th>\n",
       "      <th>asymL3</th>\n",
       "      <th>asymL4</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.167513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>-0.211429</td>\n",
       "      <td>asymL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.109948</td>\n",
       "      <td>0.119617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.082126</td>\n",
       "      <td>asymL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.284091</td>\n",
       "      <td>-0.224242</td>\n",
       "      <td>asymL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.040816</td>\n",
       "      <td>0.253886</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>199976</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>-0.289941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>199978</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.137056</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>199987</td>\n",
       "      <td>0.182320</td>\n",
       "      <td>-0.046154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>199993</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.230047</td>\n",
       "      <td>0.242938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>199996</td>\n",
       "      <td>-0.138614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.182320</td>\n",
       "      <td>asymL2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44186 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        event_num    asymL1    asymL2    asymL3    asymL4 missing\n",
       "0               0 -0.167513       NaN  0.244186 -0.211429  asymL2\n",
       "1               1  0.038462 -0.004785 -0.294118       NaN  asymL4\n",
       "5               5  0.109948  0.119617       NaN -0.082126  asymL3\n",
       "15             15 -0.187500       NaN -0.284091 -0.224242  asymL2\n",
       "18             18 -0.040816  0.253886  0.136364       NaN  asymL4\n",
       "...           ...       ...       ...       ...       ...     ...\n",
       "199976     199976  0.255102  0.037037 -0.289941       NaN  asymL4\n",
       "199978     199978  0.214286 -0.137056  0.040000       NaN  asymL4\n",
       "199987     199987  0.182320 -0.046154  0.000000       NaN  asymL4\n",
       "199993     199993  0.252525  0.230047  0.242938       NaN  asymL4\n",
       "199996     199996 -0.138614       NaN  0.088889  0.182320  asymL2\n",
       "\n",
       "[44186 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfb_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_num</th>\n",
       "      <th>asymL1</th>\n",
       "      <th>asymL2</th>\n",
       "      <th>asymL3</th>\n",
       "      <th>asymL4</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.281768</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>asymL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.122807</td>\n",
       "      <td>asymL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>-0.134021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040936</td>\n",
       "      <td>asymL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>asymL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>199986</td>\n",
       "      <td>-0.144385</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>199991</td>\n",
       "      <td>-0.049724</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>-0.164557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>199992</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>-0.176471</td>\n",
       "      <td>asymL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>199996</td>\n",
       "      <td>-0.183673</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>199997</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>-0.256281</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asymL4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44251 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        event_num    asymL1    asymL2    asymL3    asymL4 missing\n",
       "4               4       NaN  0.033175  0.281768 -0.289617  asymL1\n",
       "8               8 -0.049505       NaN  0.200000 -0.122807  asymL2\n",
       "9               9  0.177083 -0.134021  0.000000       NaN  asymL4\n",
       "11             11  0.041237  0.000000       NaN  0.040936  asymL3\n",
       "14             14 -0.056410       NaN  0.047059  0.192982  asymL2\n",
       "...           ...       ...       ...       ...       ...     ...\n",
       "199986     199986 -0.144385 -0.005236  0.297619       NaN  asymL4\n",
       "199991     199991 -0.049724  0.043956 -0.164557       NaN  asymL4\n",
       "199992     199992  0.144385       NaN  0.253012 -0.176471  asymL2\n",
       "199996     199996 -0.183673  0.179487 -0.043478       NaN  asymL4\n",
       "199997     199997  0.216080 -0.256281  0.197740       NaN  asymL4\n",
       "\n",
       "[44251 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdfnb_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdfob.getAsymmetry1DPlots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdfb['asymL1'].hist(bins=50,range=(-0.5,0.5))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef getPD(term,df):\\n    df[term].plot(kind='kde')\\n    plt.title(term)\\n    plt.xlim([-0.5, 0.5])\\n    plt.show()\\n    \\ndef getAllPDs(df):\\n    plt.figure(1)\\n    \\n    plt.subplot(221)\\n    df['asymL1'].plot(kind='kde')\\n    plt.title('asymL1', fontsize=10)\\n    plt.xlim([-0.5, 0.5])\\n    \\n    plt.subplot(222)\\n    df['asymL2'].plot(kind='kde')\\n    plt.xlim([-0.5, 0.5])\\n    plt.title('asymL2', fontsize=10)\\n    \\n    plt.subplot(223)\\n    df['asymL3'].plot(kind='kde')\\n    plt.title('asymL3', fontsize=10)\\n    plt.xlim([-0.5, 0.5])\\n    \\n    plt.subplot(224)\\n    df['asymL4'].plot(kind='kde')\\n    plt.title('asymL4', fontsize=10)\\n    plt.xlim([-0.5, 0.5])\\n    plt.tight_layout()\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def getPD(term,df):\n",
    "    df[term].plot(kind='kde')\n",
    "    plt.title(term)\n",
    "    plt.xlim([-0.5, 0.5])\n",
    "    plt.show()\n",
    "    \n",
    "def getAllPDs(df):\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    df['asymL1'].plot(kind='kde')\n",
    "    plt.title('asymL1', fontsize=10)\n",
    "    plt.xlim([-0.5, 0.5])\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    df['asymL2'].plot(kind='kde')\n",
    "    plt.xlim([-0.5, 0.5])\n",
    "    plt.title('asymL2', fontsize=10)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    df['asymL3'].plot(kind='kde')\n",
    "    plt.title('asymL3', fontsize=10)\n",
    "    plt.xlim([-0.5, 0.5])\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    df['asymL4'].plot(kind='kde')\n",
    "    plt.title('asymL4', fontsize=10)\n",
    "    plt.xlim([-0.5, 0.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "#getAllPDs(mdfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "#getAllPDs(mdfnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmdfob.reload()\\nmdfob.keepEvents(\"z_angle\",5,\"<=\")\\nmdfb4 = mdfob.events_df\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "mdfob.reload()\n",
    "mdfob.keepEvents(\"z_angle\",5,\"<=\")\n",
    "mdfb4 = mdfob.events_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "#getAllPDs(mdfb4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, the asymmetry space is continuous and not discrete we either need to **map the asymmetry space into a discretized physical space** or treat the **asymmetry space as discrete and continue with the algorithm**. We will try out both of these approaches. \n",
    "\n",
    "We will first make the assumption that asymmetry space is discrete and follow along with the algorithm.\n",
    "\n",
    "### Discrete Asymmetry Space\n",
    "\n",
    "Now, we want to generate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Sadman Ahmed Shanto"
   }
  ],
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "title": "Machine Learning in Muon Tomography",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
